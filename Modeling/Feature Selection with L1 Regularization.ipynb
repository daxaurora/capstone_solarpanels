{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Solar Panel Adoption - Feature Selection: \n",
    "## Gradient Descent Linear Regression with L1 Regularizaiton\n",
    "#### UC Berkeley MIDS\n",
    "`Team: Gabriel Hudson, Noah Levy, Laura Williams`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent using linear regression with L1 regularization and an OLS loss function is being used here for the purpose of feature selection.  The dataset input into this regression already has some feature engineering (see Data Set Up notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import statistics as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is trained on a curated dataset with some features already removed.  See Data Set Up file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load curated dataset\n",
    "deepsolar = pd.read_csv('../Datasets/deepsolar_LW1_no_CountyState.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load updated dataset after removing first set of variables\n",
    "deepsolar = pd.read_csv('../Datasets/deepsolar_LW1_S1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load updated dataset after removing two sets of variables\n",
    "deepsolar = pd.read_csv('../Datasets/deepsolar_LW2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rows and dimensions: (71305, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset rows and dimensions:\", deepsolar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a small sample dataset for testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deepsolar_sample = deepsolar.sample(frac=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small sample dataset rows and dimensions: (7130, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Small sample dataset rows and dimensions:\", deepsolar_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sample and full datasets into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset featureset shape is (7130, 63)\n",
      "Sample dataset outcome variable shape: (7130,)\n"
     ]
    }
   ],
   "source": [
    "# separate outcome variables and features - sample set\n",
    "X_sample = deepsolar_sample.drop(labels=['number_of_solar_system_per_household'], axis=1).values\n",
    "Y_sample = deepsolar_sample['number_of_solar_system_per_household'].values\n",
    "print(\"Sample dataset featureset shape is\", X_sample.shape)\n",
    "print(\"Sample dataset outcome variable shape:\", Y_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data shape:        \t(5704, 63)\n",
      "Sample training outcome variable:  \t(5704,)\n",
      "Sample test data shape:            \t(1426, 63)\n",
      "Sample test outcome variable:      \t(1426,)\n"
     ]
    }
   ],
   "source": [
    "X_sample_train, X_sample_test, \\\n",
    "Y_sample_train, Y_sample_test, = train_test_split(X_sample, Y_sample, test_size=0.2, random_state=None, shuffle=True)\n",
    "print(\"{:<35}\\t{}\".format(\"Sample training data shape:\", X_sample_train.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Sample training outcome variable:\",Y_sample_train.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Sample test data shape:\", X_sample_test.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Sample test outcome variable:\",Y_sample_test.shape ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full featureset shape is (71305, 63)\n",
      "Outcome variable shape: (71305,)\n"
     ]
    }
   ],
   "source": [
    "# separate outcome variables and features - full dataset\n",
    "X = deepsolar.drop(labels=['number_of_solar_system_per_household'], axis=1).values\n",
    "Y = deepsolar['number_of_solar_system_per_household'].values\n",
    "print(\"Full featureset shape is\", X.shape)\n",
    "print(\"Outcome variable shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:               \t(57044, 63)\n",
      "Training outcome variable:         \t(57044,)\n",
      "Test data shape:                   \t(14261, 63)\n",
      "Test outcome variable - classifier:\t(14261,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, = train_test_split(X, Y, test_size=0.2, random_state=None, shuffle=True)\n",
    "print(\"{:<35}\\t{}\".format(\"Training data shape:\", X_train.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Training outcome variable:\",Y_train.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Test data shape:\", X_test.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Test outcome variable - classifier:\",Y_test.shape ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on model parameters:  \n",
    "* Loss is OLS loss for linear regression.  \n",
    "* Penalty is L1 (lasso) to force redundant coefficients to zero.   \n",
    "* Tolerance was set .0001 to increase iterations before the model is considered converged. When testing the default, tol=None, sometimes the variables with coefficients that became zero were not intuitively correctly zero because some of them were variables that appeared in important features in the random forest model.  Setting tol=.0001 seemed to solve this problem.\n",
    "* Alpha value was chosen based on the number of coefficients that were reduced to zero.  A smaller alpha level reduced the number of coefficients reduced to zero, a larger alpha level increased the number of coefficients reduced to zero. \n",
    "\n",
    "Removing too many variables at once also seems to remove variables that have shown up in our important features list.  I tried conservative small stages to start with (detailed in the Scratch section at the end) and then chose 3 stages with more variables removed in the earlier stages.\n",
    "\n",
    "\n",
    "Only variables with coefficients reduced to zero will be removed from the dataset and tested in the model.  Variables with a small coefficient may still have some value in the dataset and will not be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(iterations, features, X_train, Y_train, X_test, Y_test):\n",
    "    # set variables\n",
    "    scores = []\n",
    "    convergences = []\n",
    "    # use mean of the outcome mean as the starting intercept\n",
    "    outcome_mean = Y_train.mean()\n",
    "    # train multiple iterations of the gradient descent regressor\n",
    "    for i in range(iterations):\n",
    "        L1 = SGDRegressor(loss='squared_loss', penalty='l1', alpha = .00002, \n",
    "                          max_iter=50, tol=.0001, learning_rate=\"constant\")\n",
    "        L1.fit(X_train, Y_train, intercept_init=outcome_mean)\n",
    "        # record results\n",
    "        scores.append(L1.score(X_test, Y_test))\n",
    "        convergences.append(L1.n_iter_)\n",
    "        coefficients_iteration = pd.DataFrame(L1.coef_, columns=[i+1], index=features)\n",
    "        if i==0:\n",
    "            coefficients = coefficients_iteration\n",
    "        else:\n",
    "            coefficients = pd.concat([coefficients, coefficients_iteration], axis=1)\n",
    "    return coefficients, scores, convergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the number of iterations\n",
    "iterations = 100\n",
    "# define the features to match with the coefficients\n",
    "features = deepsolar.drop(labels=['number_of_solar_system_per_household'], axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "coefficients, scores, convergences = feature_selection(iterations, features, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average model R squared is: 0.362412694929\n"
     ]
    }
   ],
   "source": [
    "print(\"Average model R squared is:\", stats.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of iterations to converge is: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of iterations to converge is:\", stats.mean(convergences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population_density</th>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.000784</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_less_than_high_school_rate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_high_school_graduate_rate</th>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.005347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_college_rate</th>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.008766</td>\n",
       "      <td>0.008303</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.006635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_bachelor_rate</th>\n",
       "      <td>-0.007125</td>\n",
       "      <td>-0.008915</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.004817</td>\n",
       "      <td>-0.005938</td>\n",
       "      <td>-0.005010</td>\n",
       "      <td>-0.008543</td>\n",
       "      <td>-0.007145</td>\n",
       "      <td>-0.006241</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>-0.007484</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.007260</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.006331</td>\n",
       "      <td>-0.005750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           1         2         3         4    \\\n",
       "population_density                   -0.000768 -0.000677 -0.000481 -0.000685   \n",
       "education_less_than_high_school_rate  0.000000  0.000000  0.000000  0.000000   \n",
       "education_high_school_graduate_rate   0.006253  0.005289  0.005682  0.003553   \n",
       "education_college_rate                0.004762  0.006282  0.006729  0.007712   \n",
       "education_bachelor_rate              -0.007125 -0.008915 -0.007034 -0.004817   \n",
       "\n",
       "                                           5         6         7         8    \\\n",
       "population_density                   -0.000692 -0.000859 -0.000837 -0.000782   \n",
       "education_less_than_high_school_rate  0.000000  0.000000  0.000000 -0.000085   \n",
       "education_high_school_graduate_rate   0.006542  0.004884  0.006842  0.006708   \n",
       "education_college_rate                0.008908  0.006162  0.008766  0.008303   \n",
       "education_bachelor_rate              -0.005938 -0.005010 -0.008543 -0.007145   \n",
       "\n",
       "                                           9         10     ...          91   \\\n",
       "population_density                   -0.000870 -0.000731    ...    -0.000443   \n",
       "education_less_than_high_school_rate -0.000266  0.000000    ...     0.000000   \n",
       "education_high_school_graduate_rate   0.006459  0.005827    ...     0.003560   \n",
       "education_college_rate                0.010244  0.007667    ...     0.006249   \n",
       "education_bachelor_rate              -0.006241 -0.007192    ...    -0.003985   \n",
       "\n",
       "                                           92        93        94        95   \\\n",
       "population_density                   -0.000814 -0.001176 -0.000784 -0.000679   \n",
       "education_less_than_high_school_rate  0.000000  0.000000  0.000000  0.000000   \n",
       "education_high_school_graduate_rate   0.007430  0.005522  0.004999  0.004903   \n",
       "education_college_rate                0.006861  0.007269  0.004912  0.006292   \n",
       "education_bachelor_rate              -0.007394 -0.008306 -0.006214 -0.007484   \n",
       "\n",
       "                                           96        97        98        99   \\\n",
       "population_density                   -0.001054 -0.001074 -0.001048 -0.000961   \n",
       "education_less_than_high_school_rate -0.000941  0.000000  0.000000  0.000000   \n",
       "education_high_school_graduate_rate   0.006040  0.006977  0.004997  0.005042   \n",
       "education_college_rate                0.009897  0.007999  0.006800  0.006959   \n",
       "education_bachelor_rate              -0.005523 -0.007260 -0.006695 -0.006331   \n",
       "\n",
       "                                           100  \n",
       "population_density                   -0.000721  \n",
       "education_less_than_high_school_rate  0.000000  \n",
       "education_high_school_graduate_rate   0.005347  \n",
       "education_college_rate                0.006635  \n",
       "education_bachelor_rate              -0.005750  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the coefficient list\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean of all coefficients\n",
    "coefficients_combined = pd.DataFrame(coefficients.mean(axis=1), index=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 model - remove these variables first\n",
    "Alpha value of 0.000015 used in Stage 1.  Larger alpha value of 0.00002 seemed to remove variables that have turned up in important features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 features have coefficients of zero:\n",
      "                                      0\n",
      "average_household_income            0.0\n",
      "education_professional_school_rate  0.0\n",
      "education_doctoral_rate             0.0\n",
      "race_indian_alaska_rate             0.0\n",
      "race_islander_rate                  0.0\n",
      "heating_fuel_other_rate             0.0\n",
      "electricity_price_residential       0.0\n",
      "cooling_design_temperature          0.0\n",
      "atmospheric_pressure                0.0\n",
      "age_25_34_rate                      0.0\n",
      "age_more_than_85_rate               0.0\n",
      "age_75_84_rate                      0.0\n",
      "age_15_17_rate                      0.0\n",
      "age_5_9_rate                        0.0\n",
      "occupation_manufacturing_rate       0.0\n",
      "occupation_agriculture_rate         0.0\n",
      "transportation_home_rate            0.0\n",
      "transportation_car_alone_rate       0.0\n",
      "transportation_walk_rate            0.0\n",
      "transportation_bicycle_rate         0.0\n",
      "health_insurance_public_rate        0.0\n",
      "travel_time_average                 0.0\n",
      "number_of_years_of_education        0.0\n",
      "water_percent                       0.0\n"
     ]
    }
   ],
   "source": [
    "# print list of variables whose coefficients dropped completely to zero\n",
    "coefficients_zero = coefficients_combined[coefficients_combined==0].dropna()\n",
    "print(coefficients_zero.shape[0], \"features have coefficients of zero:\")\n",
    "print(coefficients_zero)\n",
    "# create list for feature selection\n",
    "feature_drop_list = coefficients_zero.index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the variables with very small coefficients, out of curiosity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       0\n",
      "gini_index                      0.000004\n",
      "per_capita_income              -0.000031\n",
      "race_white_rate                 0.000952\n",
      "race_asian_rate                -0.000065\n",
      "employ_rate                    -0.000018\n",
      "lat                            -0.000311\n",
      "elevation                      -0.000051\n",
      "earth_temperature_amplitude     0.000982\n",
      "age_10_14_rate                 -0.000003\n",
      "dropout_16_19_inschool_rate    -0.000667\n",
      "occupation_construction_rate    0.000041\n",
      "occupation_public_rate          0.000088\n",
      "occupation_administrative_rate -0.000157\n",
      "occupation_retail_rate          0.000003\n",
      "travel_time_less_than_10_rate   0.000096\n",
      "travel_time_20_29_rate          0.000033\n",
      "age_median                      0.000447\n",
      "voting_2016_dem_win             0.000006\n",
      "voting_2012_dem_win             0.000135\n",
      "diversity                       0.000199\n",
      "rebate                          0.000262\n"
     ]
    }
   ],
   "source": [
    "# print list of variables between zero and a small coefficient\n",
    "coefficients_not_zero = coefficients_combined[coefficients_combined!=0].dropna()\n",
    "cutoff = 0.001\n",
    "coefficients_small = coefficients_not_zero[coefficients_not_zero < cutoff].dropna()\n",
    "coefficients_small = coefficients_small[coefficients_small > cutoff*-1].dropna()\n",
    "print(coefficients_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 model\n",
    "This model trained on the dataset after variables in Stage 1 were removed.\n",
    "\n",
    "Alpha value of 0.00002 used for this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 features have coefficients of zero:\n",
      "                                  0\n",
      "gini_index                      0.0\n",
      "per_capita_income               0.0\n",
      "employ_rate                     0.0\n",
      "housing_unit_median_value       0.0\n",
      "elevation                       0.0\n",
      "age_10_14_rate                  0.0\n",
      "dropout_16_19_inschool_rate     0.0\n",
      "occupation_construction_rate    0.0\n",
      "occupation_public_rate          0.0\n",
      "occupation_administrative_rate  0.0\n",
      "occupation_retail_rate          0.0\n",
      "transportation_motorcycle_rate  0.0\n",
      "travel_time_20_29_rate          0.0\n",
      "age_median                      0.0\n",
      "voting_2016_dem_win             0.0\n",
      "diversity                       0.0\n"
     ]
    }
   ],
   "source": [
    "# print list of variables whose coefficients dropped completely to zero\n",
    "coefficients_zero = coefficients_combined[coefficients_combined==0].dropna()\n",
    "print(coefficients_zero.shape[0], \"features have coefficients of zero:\")\n",
    "print(coefficients_zero)\n",
    "# create list for feature selection\n",
    "feature_drop_list = coefficients_zero.index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 model\n",
    "This model trained on the dataset after variables in Stage 2 were removed.\n",
    "\n",
    "Alpha value of 0.00002 used for this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 features have coefficients of zero:\n",
      "                                 0\n",
      "race_asian_rate                0.0\n",
      "earth_temperature_amplitude    0.0\n",
      "occupation_finance_rate        0.0\n",
      "travel_time_less_than_10_rate  0.0\n"
     ]
    }
   ],
   "source": [
    "# print list of variables whose coefficients dropped completely to zero\n",
    "coefficients_zero = coefficients_combined[coefficients_combined==0].dropna()\n",
    "print(coefficients_zero.shape[0], \"features have coefficients of zero:\")\n",
    "print(coefficients_zero)\n",
    "# create list for feature selection\n",
    "feature_drop_list = coefficients_zero.index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scratch and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_asian_rate\n",
      "earth_temperature_amplitude\n",
      "occupation_finance_rate\n",
      "travel_time_less_than_10_rate\n",
      "['race_asian_rate', 'earth_temperature_amplitude', 'occupation_finance_rate', 'travel_time_less_than_10_rate']\n"
     ]
    }
   ],
   "source": [
    "# print current drop list for easy copying elsewhere\n",
    "for i in feature_drop_list:\n",
    "    print(i)\n",
    "print(feature_drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from removing variables in stages:\n",
    "\n",
    "**Alpha value results - Stage 1**  \n",
    "* Alpha avlue of .00002 returned almost 40 variables with coefficients reduced to zero\n",
    "* Alpha value of .00001 returned about 20 variables with coefficients reduced to zero\n",
    "* Alpha value of .000005 returned about 10 variables of coefficients reduced to zero  \n",
    "\n",
    "\n",
    "**Alpha value results - Stage 2**  \n",
    "* Alpha avlue of .00005 returned almost 40 variables with coefficients reduced to zero\n",
    "* Alpha avlue of .00002 returned about 20 variables with coefficients reduced to zero\n",
    "* Alpha avlue of .000015 returned 10 variables with coefficients reduced to zero\n",
    "* Alpha avlue of .00001 returned one variable with coefficients reduced to zero\n",
    "\n",
    "**Alpha value results - Stage 3**  \n",
    "* Alpha avlue of .000025 returned about 20 variables with coefficients reduced to zero\n",
    "* Alpha avlue of .00002 returned about 10 variables with coefficients reduced to zero\n",
    "* Alpha avlue of .000015 returned 1 variable with coefficients reduced to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Stage 1 Feature Selection:**\n",
    "These 18 features were removed from the dataset:  \n",
    "average_household_income  \n",
    "education_professional_school_rate  \n",
    "race_indian_alaska_rate  \n",
    "race_islander_rate  \n",
    "heating_fuel_other_rate  \n",
    "electricity_price_residential  \n",
    "age_25_34_rate  \n",
    "age_more_than_85_rate  \n",
    "age_5_9_rate  \n",
    "occupation_manufacturing_rate  \n",
    "occupation_retail_rate  \n",
    "occupation_agriculture_rate  \n",
    "transportation_walk_rate  \n",
    "transportation_bicycle_rate  \n",
    "health_insurance_public_rate  \n",
    "travel_time_average  \n",
    "number_of_years_of_education  \n",
    "water_percent  \n",
    "\n",
    "**Stage 2 Feature Selection:**  \n",
    "gini_index  \n",
    "housing_unit_median_value  \n",
    "cooling_design_temperature  \n",
    "atmospheric_pressure  \n",
    "age_10_14_rate  \n",
    "age_15_17_rate  \n",
    "occupation_construction_rate  \n",
    "occupation_public_rate  \n",
    "occupation_administrative_rate  \n",
    "transportation_car_alone_rate  \n",
    "travel_time_less_than_10_rate  \n",
    "\n",
    "**Stage 3 Feature Selection:** . \n",
    "per_capita_income  \n",
    "education_doctoral_rate  \n",
    "race_white_rate  \n",
    "race_asian_rate  \n",
    "employ_rate  \n",
    "elevation  \n",
    "occupation_finance_rate  \n",
    "transportation_home_rate  \n",
    "transportation_motorcycle_rate  \n",
    "travel_time_20_29_rate  \n",
    "diversity  \n",
    "\n",
    "**Stage 3 repeated (additional):**\n",
    "earth_temperature_amplitude  \n",
    "age_75_84_rate  \n",
    "dropout_16_19_inschool_rate  \n",
    "age_median  \n",
    "voting_2016_dem_win  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
